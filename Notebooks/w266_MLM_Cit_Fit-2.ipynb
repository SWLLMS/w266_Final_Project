{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# w266 MLM-Cit-Fit"
      ],
      "metadata": {
        "id": "g4gCVkEY2pUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Packages and Libraries"
      ],
      "metadata": {
        "id": "Hm4Fzeaz21jp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-21LxRxDtO8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "!pip install -q transformers\n",
        "!pip install pydot\n",
        "\n",
        "# data processessing packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## NN packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# NLP packages\n",
        "from transformers import BertTokenizer,TFAutoModel, TFBertModel, BertForSequenceClassification,TFAutoModelForSequenceClassification\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1f__Xq98w24",
        "outputId": "da6bbe75-bfcf-4107-ea13-d9556682a8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing/Preprocessing data"
      ],
      "metadata": {
        "id": "h-kofif38zsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czlCHR1X9Nwq",
        "outputId": "d4f12aa3-afb1-4c91-bac5-c3e5ca7aebaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/w266/Datasets/clean_train_data.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/w266/Datasets/clean_test_data.csv')"
      ],
      "metadata": {
        "id": "9x22DycC88cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating train/val datasets\n",
        "x_train, x_val, y_train, y_val = train_test_split(train_data.text, train_data.label, test_size=0.20, random_state=42)\n",
        "# creating test datasets\n",
        "x_test = test_data.text\n",
        "y_test = test_data.label"
      ],
      "metadata": {
        "id": "7yVMqcMW-2Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\\n\")\n",
        "print(f\"x_val shape: {x_val.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\\n\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW4IaH2u-4Ns",
        "outputId": "c9448da8-fec2-444f-a1cf-d27cba6218fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (13592,)\n",
            "y_train shape: (13592,)\n",
            "\n",
            "x_val shape: (3398,)\n",
            "y_val shape: (3398,)\n",
            "\n",
            "x_test shape: (4117,)\n",
            "y_test shape: (4117,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global Variables"
      ],
      "metadata": {
        "id": "X-NH5_bI_IEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = [\"Analyst Update\",\"Fed | Central Banks\",\n",
        "        \"Company | Product News\",\"Treasuries | Corporate Debt\",\n",
        "        \"Dividend\",\"Earnings\",\"Energy | Oil\",\n",
        "        \"Financials\",\"Currencies\",\"General News | Opinion\",\n",
        "        \"Gold | Metals | Materials\",\"IPO\",\"Legal | Regulation\",\n",
        "        \"M&A | Investments\",\"Macro\",\"Markets\",\"Politics\",\n",
        "        \"Personnel Change\",\"Stock Commentary\", \"Stock Movement\"]"
      ],
      "metadata": {
        "id": "Q0Ce4-tQ_KSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating of learning rate schedule\n",
        "num_epochs = 5\n",
        "num_train_steps = len(x_train) * num_epochs\n",
        "lr_scheduler = PolynomialDecay(\n",
        "    initial_learning_rate=5e-5,\n",
        "    end_learning_rate=0.,\n",
        "    decay_steps=num_train_steps\n",
        ")"
      ],
      "metadata": {
        "id": "E381P41W_HoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "Zlvp_nxUvGbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for creating tokenized data and outputs for models\n",
        "\n",
        "def create_datasets(tokenizer, train, val, test):\n",
        "  # Variables\n",
        "  # train/val/test = datasets to encode\n",
        "  # tokenizer = bert tokenizer\n",
        "\n",
        "  train_encodings = tokenizer(list(train), padding=True, return_tensors='tf')\n",
        "  valid_encodings = tokenizer(list(val), padding=True, return_tensors='tf')\n",
        "  test_encodings = tokenizer(list(test),padding=True, return_tensors='tf')\n",
        "\n",
        "\n",
        "  return train_encodings, valid_encodings, test_encodings\n"
      ],
      "metadata": {
        "id": "oyZOLw8gvgPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Function for creating model\n",
        "def create_bert_multiclass_model(model,\n",
        "                                 num_classes = 20,\n",
        "                                 hidden_size = 201,\n",
        "                                 dropout=0.3,\n",
        "                                 learning_rate=0.00005,\n",
        "                                 activation='softmax'):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the Pooler Output for classification purposes.\n",
        "    \"\"\"\n",
        "\n",
        "    bert_model = model\n",
        "\n",
        "    # building bert inputs\n",
        "    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='input_ids_layer')\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}\n",
        "\n",
        "    # building bert model\n",
        "    bert_out = bert_model(bert_inputs)\n",
        "    pooler_output = bert_out[1] # bert_out.pooler_output\n",
        "\n",
        "    # building hidden layers\n",
        "    last_hidden_output = tf.keras.layers.Dense(hidden_size, activation='relu', name='last_hidden_output')(pooler_output)\n",
        "    last_hidden_output = tf.keras.layers.Dropout(dropout, name='dropout')(last_hidden_output)\n",
        "    bert_cls_prediction = keras.layers.Dense(num_classes, activation=activation, name='cls_output')(last_hidden_output)\n",
        "\n",
        "    # compiling model\n",
        "    bert_cls_model = keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=bert_cls_prediction)\n",
        "    bert_cls_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                           metrics='accuracy')\n",
        "\n",
        "    ### END YOUR CODE\n",
        "    return bert_cls_model"
      ],
      "metadata": {
        "id": "QSgSDxoWvF12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MLM-Cit-Fit\n",
        "Masked Language Modeling, Cluster Inter-Training, and Fit-Tuning Strategies"
      ],
      "metadata": {
        "id": "Qxq78CHg3hHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###BERT-Base"
      ],
      "metadata": {
        "id": "io0zrknV3k11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading BERT-base-MLM-Cit tokenizer/model\n",
        "bert_mlm_cit_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Tokenizer')\n",
        "bert_mlm_cit_model = TFBertModel.from_pretrained(\"/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit\")"
      ],
      "metadata": {
        "id": "-3ThK0iTx-xI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140ba048-e809-4e65-95cc-e32d5264d0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating BERT-base-MLM-Cit encodings\n",
        "bert_mlm_cit_train_encodings, bert_mlm_cit_valid_encodings, bert_mlm_cit_test_encodings = create_datasets(bert_mlm_cit_tokenizer, x_train, x_val, x_test)"
      ],
      "metadata": {
        "id": "Mv6GuJFdx-cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating BERT-base-MLM-Cit-Fit model\n",
        "bert_mlm_cit_fit = create_bert_multiclass_model(bert_mlm_cit_model, num_classes=20, learning_rate=lr_scheduler)"
      ],
      "metadata": {
        "id": "yYVac3Cgx-aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running BERT-base-MLM-Cit-Fit model\n",
        "bert_mlm_cit_fit_model_history = bert_mlm_cit_fit.fit([bert_mlm_cit_train_encodings.input_ids, bert_mlm_cit_train_encodings.token_type_ids, bert_mlm_cit_train_encodings.attention_mask],\n",
        "                                                  y_train,\n",
        "                                                  validation_data=([bert_mlm_cit_valid_encodings.input_ids, bert_mlm_cit_valid_encodings.token_type_ids, bert_mlm_cit_valid_encodings.attention_mask],\n",
        "                                                  y_val),\n",
        "                                                  batch_size=8,\n",
        "                                                  epochs=5)"
      ],
      "metadata": {
        "id": "CP8v8B15ynjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653a99a2-a441-4fce-8751-fc8b623e705f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1699/1699 [==============================] - 147s 62ms/step - loss: 0.2029 - accuracy: 0.9553 - val_loss: 0.5702 - val_accuracy: 0.8817\n",
            "Epoch 2/5\n",
            "1699/1699 [==============================] - 77s 45ms/step - loss: 0.1230 - accuracy: 0.9715 - val_loss: 0.6427 - val_accuracy: 0.8776\n",
            "Epoch 3/5\n",
            "1699/1699 [==============================] - 76s 45ms/step - loss: 0.1059 - accuracy: 0.9742 - val_loss: 0.6478 - val_accuracy: 0.8858\n",
            "Epoch 4/5\n",
            "1699/1699 [==============================] - 74s 43ms/step - loss: 0.0920 - accuracy: 0.9773 - val_loss: 0.6733 - val_accuracy: 0.8829\n",
            "Epoch 5/5\n",
            "1699/1699 [==============================] - 73s 43ms/step - loss: 0.0768 - accuracy: 0.9818 - val_loss: 0.7251 - val_accuracy: 0.8817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating BERT-base-MLM-Cit-Fit models\n",
        "bert_mlm_cit_fit_results = bert_mlm_cit_fit.evaluate([bert_mlm_cit_test_encodings.input_ids, bert_mlm_cit_test_encodings.token_type_ids, bert_mlm_cit_test_encodings.attention_mask],\n",
        "                                         y_test,\n",
        "                                         batch_size=8)\n",
        "\n",
        "print(f\"Model accuracy: {bert_mlm_cit_fit_results[1]}\\n\"+\n",
        "      f\"Model loss: {bert_mlm_cit_fit_results[0]}\")\n"
      ],
      "metadata": {
        "id": "eT6jRxFfx-Xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48734c24-44a6-4ddd-d0c6-7413d40e1e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "515/515 [==============================] - 16s 25ms/step - loss: 0.6950 - accuracy: 0.8829\n",
            "Model accuracy: 0.8829244375228882\n",
            "Model loss: 0.6949968338012695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing BERT-base-MLM-Cit-Fit F1 metric\n",
        "bert_mlm_cit_fit_y_pred = bert_mlm_cit_fit.predict([bert_mlm_cit_test_encodings.input_ids, bert_mlm_cit_test_encodings.token_type_ids, bert_mlm_cit_test_encodings.attention_mask])\n",
        "pred_bert_mlm_cit_fit_model = tf.argmax(bert_mlm_cit_fit_y_pred, axis=-1)\n",
        "\n",
        "print(classification_report(y_test, pred_bert_mlm_cit_fit_model.numpy(), target_names=target_names, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "id": "gtMY9d59ykT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "101f7999-7360-4dec-974b-0cf691d58a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 9s 46ms/step\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "             Analyst Update     0.9259    0.6849    0.7874        73\n",
            "        Fed | Central Banks     0.8850    0.9346    0.9091       214\n",
            "     Company | Product News     0.9052    0.8850    0.8950       852\n",
            "Treasuries | Corporate Debt     0.9333    0.7273    0.8175        77\n",
            "                   Dividend     0.9500    0.9794    0.9645        97\n",
            "                   Earnings     0.9444    0.9835    0.9636       242\n",
            "               Energy | Oil     0.9167    0.8288    0.8705       146\n",
            "                 Financials     0.9459    0.8750    0.9091       160\n",
            "                 Currencies     0.7692    0.9375    0.8451        32\n",
            "     General News | Opinion     0.7895    0.8036    0.7965       336\n",
            "  Gold | Metals | Materials     0.5000    0.9231    0.6486        13\n",
            "                        IPO     0.9286    0.9286    0.9286        14\n",
            "         Legal | Regulation     0.9000    0.8319    0.8646       119\n",
            "          M&A | Investments     0.7863    0.7931    0.7897       116\n",
            "                      Macro     0.8292    0.8892    0.8581       415\n",
            "                    Markets     0.8594    0.8800    0.8696       125\n",
            "                   Politics     0.9008    0.9116    0.9062       249\n",
            "           Personnel Change     0.9167    0.8839    0.9000       112\n",
            "           Stock Commentary     0.8991    0.9110    0.9050       528\n",
            "             Stock Movement     0.9040    0.9086    0.9063       197\n",
            "\n",
            "                   accuracy                         0.8829      4117\n",
            "                  macro avg     0.8695    0.8750    0.8667      4117\n",
            "               weighted avg     0.8853    0.8829    0.8829      4117\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpointing BERT-base-MLM-Cit-Fit model\n",
        "bert_mlm_cit_model.save_pretrained('/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit')\n",
        "\n",
        "# Checkpointing BERT-base-MLM-Cit-Fit tokenizer\n",
        "bert_mlm_cit_tokenizer.save_pretrained('/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit-tokenizer')"
      ],
      "metadata": {
        "id": "iwxGYpziykJ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32191f6b-e4fe-4123-913d-dfa554bd71cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit-tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit-tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit-tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/BERT-base-MLM-Cit-Fit-tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FinBert"
      ],
      "metadata": {
        "id": "nYxl1e5z3pX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading FinBert-MLM-Cit tokenizer/model\n",
        "finbert_mlm_cit_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Tokenizer')\n",
        "finbert_mlm_cit_model = TFBertModel.from_pretrained(\"/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit\")"
      ],
      "metadata": {
        "id": "GbAjsxbK3PdD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99204aed-2969-4d4a-f47a-3750939430c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertModel.\n",
            "\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at /content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating FinBert-MLM-Cit encodings\n",
        "finbert_mlm_cit_train_encodings, finbert_mlm_cit_valid_encodings, finbert_mlm_cit_test_encodings = create_datasets(finbert_mlm_cit_tokenizer, x_train, x_val, x_test)"
      ],
      "metadata": {
        "id": "JEqCHe1H0Nl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating FinBert-MLM-Cit-Fit  model\n",
        "finbert_mlm_cit_fit = create_bert_multiclass_model(finbert_mlm_cit_model, num_classes=20, learning_rate=lr_scheduler)"
      ],
      "metadata": {
        "id": "zvKHJo3j0NiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running FinBert-MLM-Cit-Fit model\n",
        "finbert_mlm_cit_fit_model_history = finbert_mlm_cit_fit.fit([finbert_mlm_cit_train_encodings.input_ids, finbert_mlm_cit_train_encodings.token_type_ids, finbert_mlm_cit_train_encodings.attention_mask],\n",
        "                                                  y_train,\n",
        "                                                  validation_data=([finbert_mlm_cit_valid_encodings.input_ids, finbert_mlm_cit_valid_encodings.token_type_ids, finbert_mlm_cit_valid_encodings.attention_mask],\n",
        "                                                  y_val),\n",
        "                                                  batch_size=8,\n",
        "                                                  epochs=5)"
      ],
      "metadata": {
        "id": "uPHiQbMs0NfL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b82b85-23e1-4d3a-c4b3-f84e8b2363eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1699/1699 [==============================] - 137s 58ms/step - loss: 0.2033 - accuracy: 0.9547 - val_loss: 0.7942 - val_accuracy: 0.8549\n",
            "Epoch 2/5\n",
            "1699/1699 [==============================] - 74s 43ms/step - loss: 0.1381 - accuracy: 0.9684 - val_loss: 0.7499 - val_accuracy: 0.8511\n",
            "Epoch 3/5\n",
            "1699/1699 [==============================] - 73s 43ms/step - loss: 0.1247 - accuracy: 0.9718 - val_loss: 0.6698 - val_accuracy: 0.8758\n",
            "Epoch 4/5\n",
            "1699/1699 [==============================] - 73s 43ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 0.7297 - val_accuracy: 0.8593\n",
            "Epoch 5/5\n",
            "1699/1699 [==============================] - 72s 42ms/step - loss: 0.0964 - accuracy: 0.9768 - val_loss: 0.7112 - val_accuracy: 0.8702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating FinBert-MLM-Cit-Fit models\n",
        "finbert_mlm_cit_fit_results = finbert_mlm_cit_fit.evaluate([finbert_mlm_cit_test_encodings.input_ids, finbert_mlm_cit_test_encodings.token_type_ids, finbert_mlm_cit_test_encodings.attention_mask],\n",
        "                                         y_test,\n",
        "                                         batch_size=8)\n",
        "\n",
        "print(f\"Model accuracy: {finbert_mlm_cit_fit_results[1]}\\n\"+\n",
        "      f\"Model loss: {finbert_mlm_cit_fit_results[0]}\")\n"
      ],
      "metadata": {
        "id": "TyyKoC1O0Nc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a02169-bd1c-4931-f935-48c91e77854d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "515/515 [==============================] - 15s 23ms/step - loss: 0.7672 - accuracy: 0.8594\n",
            "Model accuracy: 0.8593636155128479\n",
            "Model loss: 0.7672273516654968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing FinBert-MLM-Cit-Fit metric\n",
        "finbert_mlm_cit_fit_y_pred = finbert_mlm_cit_fit.predict([finbert_mlm_cit_test_encodings.input_ids, finbert_mlm_cit_test_encodings.token_type_ids, finbert_mlm_cit_test_encodings.attention_mask])\n",
        "pred_finbert_mlm_cit_fit_model = tf.argmax(finbert_mlm_cit_fit_y_pred, axis=-1)\n",
        "\n",
        "print(classification_report(y_test, pred_finbert_mlm_cit_fit_model.numpy(), target_names=target_names, digits=4))\n",
        "\n"
      ],
      "metadata": {
        "id": "8F4v6_xE0Naj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54521db-d2fc-479e-c50d-b96511efa63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 8s 39ms/step\n",
            "                             precision    recall  f1-score   support\n",
            "\n",
            "             Analyst Update     0.9333    0.7671    0.8421        73\n",
            "        Fed | Central Banks     0.8155    0.8879    0.8501       214\n",
            "     Company | Product News     0.8483    0.8862    0.8668       852\n",
            "Treasuries | Corporate Debt     0.8767    0.8312    0.8533        77\n",
            "                   Dividend     0.9792    0.9691    0.9741        97\n",
            "                   Earnings     0.9237    0.9504    0.9369       242\n",
            "               Energy | Oil     0.8125    0.8904    0.8497       146\n",
            "                 Financials     0.9211    0.8750    0.8974       160\n",
            "                 Currencies     0.8235    0.8750    0.8485        32\n",
            "     General News | Opinion     0.8247    0.7143    0.7656       336\n",
            "  Gold | Metals | Materials     0.5652    1.0000    0.7222        13\n",
            "                        IPO     0.8667    0.9286    0.8966        14\n",
            "         Legal | Regulation     0.7692    0.8403    0.8032       119\n",
            "          M&A | Investments     0.8830    0.7155    0.7905       116\n",
            "                      Macro     0.7806    0.8916    0.8324       415\n",
            "                    Markets     0.8217    0.8480    0.8346       125\n",
            "                   Politics     0.8884    0.8635    0.8758       249\n",
            "           Personnel Change     0.9118    0.8304    0.8692       112\n",
            "           Stock Commentary     0.9157    0.8845    0.8998       528\n",
            "             Stock Movement     0.9437    0.7665    0.8459       197\n",
            "\n",
            "                   accuracy                         0.8594      4117\n",
            "                  macro avg     0.8552    0.8608    0.8527      4117\n",
            "               weighted avg     0.8632    0.8594    0.8591      4117\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpointing FinBert-MLM-Cit-Fit model\n",
        "finbert_mlm_cit_model.save_pretrained('/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit')\n",
        "\n",
        "# Checkpointing FinBert-MLM-Cit-Fit tokenizer\n",
        "finbert_mlm_cit_tokenizer.save_pretrained('/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit-tokenizer')"
      ],
      "metadata": {
        "id": "hgh9aNT80NX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250d15c8-3a42-4643-a4d6-ca3377e68a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit-tokenizer/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit-tokenizer/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit-tokenizer/vocab.txt',\n",
              " '/content/drive/MyDrive/w266/Model-Weights/FinBert-MLM-Cit-Fit-tokenizer/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdheLHp20NVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "svUiylf50NSu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}