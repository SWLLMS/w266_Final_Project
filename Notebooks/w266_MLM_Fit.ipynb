{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# w266 Masked language modeling (MLM) & learning rate fine-tuning (Fit)"],"metadata":{"id":"g4gCVkEY2pUe"}},{"cell_type":"markdown","source":["## Packages and Libraries"],"metadata":{"id":"Hm4Fzeaz21jp"}},{"cell_type":"code","source":[],"metadata":{"id":"-21LxRxDtO8Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Installs\n","!pip install -q transformers\n","!pip install pydot\n","\n","# data processessing packages\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","## NN packages\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import backend as K\n","from tensorflow.keras.optimizers.schedules import PolynomialDecay\n","from sklearn.metrics import classification_report\n","\n","# NLP packages\n","from transformers import BertTokenizer,TFAutoModel, TFBertModel, BertForSequenceClassification,TFAutoModelForSequenceClassification\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1f__Xq98w24","outputId":"77a80c7a-380e-4c61-cf7e-73c1f961f1f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.0)\n"]}]},{"cell_type":"markdown","source":["### Mounting Drive"],"metadata":{"id":"Kyv6j-KG9Lp2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czlCHR1X9Nwq","outputId":"0f5469bd-9494-44e1-899c-0ff6942663ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Importing/Preprocessing data"],"metadata":{"id":"h-kofif38zsf"}},{"cell_type":"code","source":["train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/w266/data/clean_train_data.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/w266/data/clean_test_data.csv')"],"metadata":{"id":"9x22DycC88cR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating train/val datasets\n","x_train, x_val, y_train, y_val = train_test_split(train_data.text, train_data.label, test_size=0.20, random_state=42)\n","# creating test datasets\n","x_test = test_data.text\n","y_test = test_data.label"],"metadata":{"id":"7yVMqcMW-2Pv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"x_train shape: {x_train.shape}\")\n","print(f\"y_train shape: {y_train.shape}\\n\")\n","print(f\"x_val shape: {x_val.shape}\")\n","print(f\"y_val shape: {y_val.shape}\\n\")\n","print(f\"x_test shape: {x_test.shape}\")\n","print(f\"y_test shape: {y_test.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EW4IaH2u-4Ns","outputId":"6a15face-ef14-4e42-9721-9bb091506312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (13592,)\n","y_train shape: (13592,)\n","\n","x_val shape: (3398,)\n","y_val shape: (3398,)\n","\n","x_test shape: (4117,)\n","y_test shape: (4117,)\n"]}]},{"cell_type":"markdown","source":["## Global Variables"],"metadata":{"id":"X-NH5_bI_IEw"}},{"cell_type":"code","source":["target_names = [\"Analyst Update\",\"Fed | Central Banks\",\n","        \"Company | Product News\",\"Treasuries | Corporate Debt\",\n","        \"Dividend\",\"Earnings\",\"Energy | Oil\",\n","        \"Financials\",\"Currencies\",\"General News | Opinion\",\n","        \"Gold | Metals | Materials\",\"IPO\",\"Legal | Regulation\",\n","        \"M&A | Investments\",\"Macro\",\"Markets\",\"Politics\",\n","        \"Personnel Change\",\"Stock Commentary\", \"Stock Movement\"]"],"metadata":{"id":"Q0Ce4-tQ_KSq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating of learning rate schedule\n","num_epochs = 5\n","num_train_steps = len(x_train) * num_epochs\n","lr_scheduler = PolynomialDecay(\n","    initial_learning_rate=5e-5,\n","    end_learning_rate=0.,\n","    decay_steps=num_train_steps\n",")"],"metadata":{"id":"E381P41W_HoO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Utility Functions"],"metadata":{"id":"Zlvp_nxUvGbv"}},{"cell_type":"code","source":["#Function for creating tokenized data and outputs for models\n","\n","def create_datasets(tokenizer, train, val, test):\n","  # Variables\n","  # train/val/test = datasets to encode\n","  # tokenizer = bert tokenizer\n","\n","  train_encodings = tokenizer(list(train), padding=True, return_tensors='tf')\n","  valid_encodings = tokenizer(list(val), padding=True, return_tensors='tf')\n","  test_encodings = tokenizer(list(test),padding=True, return_tensors='tf')\n","\n","\n","  return train_encodings, valid_encodings, test_encodings\n"],"metadata":{"id":"oyZOLw8gvgPV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" # Function for creating model\n","def create_bert_multiclass_model(model,\n","                                 num_classes = 20,\n","                                 hidden_size = 201,\n","                                 dropout=0.3,\n","                                 learning_rate=0.00005,\n","                                 activation='softmax'):\n","    \"\"\"\n","    Build a simple classification model with BERT. Use the Pooler Output for classification purposes.\n","    \"\"\"\n","\n","    bert_model = model\n","\n","    # building bert inputs\n","    input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='input_ids_layer')\n","    token_type_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='token_type_ids_layer')\n","    attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int64, name='attention_mask_layer')\n","\n","    bert_inputs = {'input_ids': input_ids,\n","                   'token_type_ids': token_type_ids,\n","                   'attention_mask': attention_mask}\n","\n","    # building bert model\n","    bert_out = bert_model(bert_inputs)\n","    pooler_output = bert_out[1] # bert_out.pooler_output\n","\n","    # building hidden layers\n","    last_hidden_output = tf.keras.layers.Dense(hidden_size, activation='relu', name='last_hidden_output')(pooler_output)\n","    last_hidden_output = tf.keras.layers.Dropout(dropout, name='dropout')(last_hidden_output)\n","    bert_cls_prediction = keras.layers.Dense(num_classes, activation=activation, name='cls_output')(last_hidden_output)\n","\n","    # compiling model\n","    bert_cls_model = keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=bert_cls_prediction)\n","    bert_cls_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n","                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","                           metrics='accuracy')\n","\n","    ### END YOUR CODE\n","    return bert_cls_model"],"metadata":{"id":"QSgSDxoWvF12"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##MLM-Fit\n","Masked Language Model and Fit-Tuning Strategies"],"metadata":{"id":"koUPI4Yr247x"}},{"cell_type":"markdown","source":["### BERT-Base"],"metadata":{"id":"H3NStbnG2_8O"}},{"cell_type":"code","source":["# Loading BERT-base-MLM tokenizer/model\n","bert_mlm_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/Colab Notebooks/w266/Model Weights/BERT-base-MLM-tokenizer')\n","bert_mlm_model = TFBertModel.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/w266/Model Weights/BERT-base-MLM\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8muPaSPaZkJ","outputId":"395e2f0d-0ea3-40ef-ba9a-7d2a95d594d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/w266/Model Weights/BERT-base-MLM were not used when initializing TFBertModel: ['mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertModel were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/w266/Model Weights/BERT-base-MLM and are newly initialized: ['bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Creating BERT-base-MLM encodings\n","bert_mlm_train_encodings, bert_mlm_valid_encodings, bert_mlm_test_encodings = create_datasets(bert_mlm_tokenizer, x_train, x_val, x_test)"],"metadata":{"id":"QBTXFMmqbN_i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating BERT-base-MLM-Fit model\n","bert_mlm_fit = create_bert_multiclass_model(bert_mlm_model, num_classes=20, learning_rate=lr_scheduler)"],"metadata":{"id":"vTEOLlscbP3w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Running BERT-base-MLM-Fit model\n","bert_mlm_fit_history = bert_mlm_fit.fit([bert_mlm_train_encodings.input_ids, bert_mlm_train_encodings.token_type_ids, bert_mlm_train_encodings.attention_mask],\n","                                                  y_train,\n","                                                  validation_data=([bert_mlm_valid_encodings.input_ids, bert_mlm_valid_encodings.token_type_ids, bert_mlm_valid_encodings.attention_mask],\n","                                                  y_val),\n","                                                  batch_size=8,\n","                                                  epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F89AfDvKbN31","outputId":"1f1157ce-5823-4ea3-b3fb-691e3d38afa2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1699/1699 [==============================] - 136s 57ms/step - loss: 0.7502 - accuracy: 0.7882 - val_loss: 0.5028 - val_accuracy: 0.8617\n","Epoch 2/5\n","1699/1699 [==============================] - 74s 44ms/step - loss: 0.3235 - accuracy: 0.9064 - val_loss: 0.4008 - val_accuracy: 0.8952\n","Epoch 3/5\n","1699/1699 [==============================] - 70s 41ms/step - loss: 0.2018 - accuracy: 0.9408 - val_loss: 0.4522 - val_accuracy: 0.8799\n","Epoch 4/5\n","1699/1699 [==============================] - 72s 42ms/step - loss: 0.1528 - accuracy: 0.9553 - val_loss: 0.5074 - val_accuracy: 0.8911\n","Epoch 5/5\n","1699/1699 [==============================] - 70s 41ms/step - loss: 0.1144 - accuracy: 0.9682 - val_loss: 0.5603 - val_accuracy: 0.8802\n"]}]},{"cell_type":"code","source":["# Evaluating BERT-base-MLM-Fit models\n","bert_mlm_fit_results = bert_mlm_fit.evaluate([bert_mlm_test_encodings.input_ids, bert_mlm_test_encodings.token_type_ids, bert_mlm_test_encodings.attention_mask],\n","                                         y_test,\n","                                         batch_size=8)\n","\n","print(f\"Model accuracy: {bert_mlm_fit_results[1]}\\n\"+\n","      f\"Model loss: {bert_mlm_fit_results[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNQwvSombUD4","outputId":"0cbd5591-bdcc-4e93-cfcd-fd8066021a0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["515/515 [==============================] - 16s 24ms/step - loss: 0.5840 - accuracy: 0.8786\n","Model accuracy: 0.8785523176193237\n","Model loss: 0.583951473236084\n"]}]},{"cell_type":"code","source":["# Computing BERT-base-MLM-Fit F1 metric\n","bert_mlm_fit_y_pred = bert_mlm_fit.predict([bert_mlm_test_encodings.input_ids, bert_mlm_test_encodings.token_type_ids, bert_mlm_test_encodings.attention_mask])\n","pred_bert_mlm_fit_model = tf.argmax(bert_mlm_fit_y_pred, axis=-1)\n","\n","print(classification_report(y_test, pred_bert_mlm_fit_model.numpy(), target_names=target_names, digits=4))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikGPmkzHbNzC","outputId":"5c1aa120-f0cc-4c56-b53c-e44d2953db93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["129/129 [==============================] - 9s 46ms/step\n","                             precision    recall  f1-score   support\n","\n","             Analyst Update     0.9737    0.5068    0.6667        73\n","        Fed | Central Banks     0.8628    0.9112    0.8864       214\n","     Company | Product News     0.8418    0.9366    0.8867       852\n","Treasuries | Corporate Debt     0.8841    0.7922    0.8356        77\n","                   Dividend     0.9588    0.9588    0.9588        97\n","                   Earnings     0.9750    0.9669    0.9710       242\n","               Energy | Oil     0.7733    0.7945    0.7838       146\n","                 Financials     0.8750    0.9187    0.8963       160\n","                 Currencies     0.8966    0.8125    0.8525        32\n","     General News | Opinion     0.8651    0.7440    0.8000       336\n","  Gold | Metals | Materials     1.0000    0.3077    0.4706        13\n","                        IPO     0.8667    0.9286    0.8966        14\n","         Legal | Regulation     0.8595    0.8739    0.8667       119\n","          M&A | Investments     0.9048    0.8190    0.8597       116\n","                      Macro     0.8747    0.8578    0.8662       415\n","                    Markets     0.8909    0.7840    0.8340       125\n","                   Politics     0.9091    0.9237    0.9163       249\n","           Personnel Change     0.9633    0.9375    0.9502       112\n","           Stock Commentary     0.9165    0.8939    0.9051       528\n","             Stock Movement     0.8170    0.9289    0.8694       197\n","\n","                   accuracy                         0.8786      4117\n","                  macro avg     0.8954    0.8299    0.8486      4117\n","               weighted avg     0.8812    0.8786    0.8766      4117\n","\n"]}]},{"cell_type":"markdown","source":["###FinBert"],"metadata":{"id":"ckvEmYu53Fn6"}},{"cell_type":"code","source":["# Loading FinBert-MLM tokenizer/model\n","finbert_mlm_tokenizer = BertTokenizer.from_pretrained('/content/drive/MyDrive/Colab Notebooks/w266/Model Weights/FinBert-MLM-tokenizer')\n","finbert_mlm_model = TFBertModel.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/w266/Model Weights/FinBert-MLM\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sdsyy1WIaSOn","outputId":"8929cd60-94e3-4b2e-9b56-98c03d1f49c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/w266/Model Weights/FinBert-MLM were not used when initializing TFBertModel: ['mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFBertModel were not initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/w266/Model Weights/FinBert-MLM and are newly initialized: ['bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Creating FinBert-MLM encodings\n","finbert_mlm_train_encodings, finbert_mlm_valid_encodings, finbert_mlm_test_encodings = create_datasets(finbert_mlm_tokenizer, x_train, x_val, x_test)"],"metadata":{"id":"noVH6mqQbfD0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creating FinBert-MLM model\n","finbert_mlm_fit = create_bert_multiclass_model(finbert_mlm_model, num_classes=20, learning_rate=lr_scheduler)"],"metadata":{"id":"ZNQHyLwPbe-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Running FinBert-MLM model\n","finbert_mlm_fit_history = finbert_mlm_fit.fit([finbert_mlm_train_encodings.input_ids, finbert_mlm_train_encodings.token_type_ids, finbert_mlm_train_encodings.attention_mask],\n","                                                  y_train,\n","                                                  validation_data=([finbert_mlm_valid_encodings.input_ids, finbert_mlm_valid_encodings.token_type_ids, finbert_mlm_valid_encodings.attention_mask],\n","                                                  y_val),\n","                                                  batch_size=8,\n","                                                  epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1pPBRVNbe4X","outputId":"0cdc9b4c-9056-40ac-afed-c58a625afee7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1699/1699 [==============================] - 135s 57ms/step - loss: 0.7159 - accuracy: 0.7894 - val_loss: 0.5097 - val_accuracy: 0.8546\n","Epoch 2/5\n","1699/1699 [==============================] - 71s 42ms/step - loss: 0.3102 - accuracy: 0.9115 - val_loss: 0.4282 - val_accuracy: 0.8832\n","Epoch 3/5\n","1699/1699 [==============================] - 71s 42ms/step - loss: 0.2065 - accuracy: 0.9403 - val_loss: 0.4394 - val_accuracy: 0.8899\n","Epoch 4/5\n","1699/1699 [==============================] - 70s 41ms/step - loss: 0.1456 - accuracy: 0.9585 - val_loss: 0.5752 - val_accuracy: 0.8755\n","Epoch 5/5\n","1699/1699 [==============================] - 70s 41ms/step - loss: 0.1208 - accuracy: 0.9676 - val_loss: 0.5547 - val_accuracy: 0.8773\n"]}]},{"cell_type":"code","source":["# Evaluating FinBert-MLM models\n","finbert_mlm_fit_results = finbert_mlm_fit.evaluate([finbert_mlm_test_encodings.input_ids, finbert_mlm_test_encodings.token_type_ids, finbert_mlm_test_encodings.attention_mask],\n","                                         y_test,\n","                                         batch_size=8)\n","\n","print(f\"Model accuracy: {finbert_mlm_fit_results[1]}\\n\"+\n","      f\"Model loss: {finbert_mlm_fit_results[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eYvKTTxRbezl","outputId":"b674f2fa-3e61-4f9d-c5d9-b5b0d439d9e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["515/515 [==============================] - 15s 23ms/step - loss: 0.5805 - accuracy: 0.8679\n","Model accuracy: 0.8678649663925171\n","Model loss: 0.5805019736289978\n"]}]},{"cell_type":"code","source":["# Computing FinBert-MLM F1 metric\n","finbert_mlm_fit_y_pred = finbert_mlm_fit.predict([finbert_mlm_test_encodings.input_ids, finbert_mlm_test_encodings.token_type_ids, finbert_mlm_test_encodings.attention_mask])\n","pred_finbert_mlm_fit_model = tf.argmax(finbert_mlm_fit_y_pred, axis=-1)\n","\n","print(classification_report(y_test, pred_finbert_mlm_fit_model.numpy(), target_names=target_names, digits=4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M_BHo6KCbeu-","outputId":"4e5c5bda-c92d-489c-db74-dba804319db7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["129/129 [==============================] - 8s 37ms/step\n","                             precision    recall  f1-score   support\n","\n","             Analyst Update     0.8000    0.7123    0.7536        73\n","        Fed | Central Banks     0.9344    0.7991    0.8615       214\n","     Company | Product News     0.9302    0.8451    0.8856       852\n","Treasuries | Corporate Debt     0.7470    0.8052    0.7750        77\n","                   Dividend     0.9792    0.9691    0.9741        97\n","                   Earnings     0.9532    0.9256    0.9392       242\n","               Energy | Oil     0.8516    0.9041    0.8771       146\n","                 Financials     0.7906    0.9437    0.8604       160\n","                 Currencies     0.7692    0.9375    0.8451        32\n","     General News | Opinion     0.7051    0.8185    0.7576       336\n","  Gold | Metals | Materials     0.7500    0.9231    0.8276        13\n","                        IPO     0.8750    1.0000    0.9333        14\n","         Legal | Regulation     0.8045    0.8992    0.8492       119\n","          M&A | Investments     0.8571    0.8276    0.8421       116\n","                      Macro     0.8571    0.8530    0.8551       415\n","                    Markets     0.8413    0.8480    0.8446       125\n","                   Politics     0.9234    0.8715    0.8967       249\n","           Personnel Change     0.9182    0.9018    0.9099       112\n","           Stock Commentary     0.9365    0.8939    0.9147       528\n","             Stock Movement     0.7593    0.9289    0.8356       197\n","\n","                   accuracy                         0.8679      4117\n","                  macro avg     0.8492    0.8804    0.8619      4117\n","               weighted avg     0.8747    0.8679    0.8692      4117\n","\n"]}]}]}